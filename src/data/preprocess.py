import pandas as pd
import numpy as np
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import spacy
from tqdm import tqdm
import logging

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class TweetPreprocessor:
    def __init__(self, language='french'):
        """
        Initialise le pr√©processeur de tweets.
        
        Args:
            language (str): Langue des tweets ('french' ou 'english')
        """
        self.language = language
        self.stop_words = set(stopwords.words('french' if language == 'french' else 'english'))
        self.lemmatizer = WordNetLemmatizer()
        self.nlp = spacy.load('fr_core_news_md' if language == 'french' else 'en_core_web_md')
        
    def remove_urls(self, text):
        """Supprime les URLs du texte."""
        url_pattern = re.compile(r'https?://\S+|www\.\S+')
        return url_pattern.sub('', text)
    
    def remove_emojis(self, text):
        """Supprime les emojis du texte."""
        emoji_pattern = re.compile("["
            u"\U0001F600-\U0001F64F"  # emoticons
            u"\U0001F300-\U0001F5FF"  # symbols & pictographs
            u"\U0001F680-\U0001F6FF"  # transport & map symbols
            u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
            u"\U00002702-\U000027B0"
            u"\U000024C2-\U0001F251"
            "]+", flags=re.UNICODE)
        return emoji_pattern.sub('', text)
    
    def remove_mentions_and_hashtags(self, text):
        """Supprime les mentions (@) et les hashtags (#)."""
        text = re.sub(r'@\w+', '', text)
        text = re.sub(r'#\w+', '', text)
        return text
    
    def remove_special_chars(self, text):
        """Supprime les caract√®res sp√©ciaux tout en gardant les accents."""
        return re.sub(r'[^\w\s]', ' ', text)
    
    def lemmatize_text(self, text):
        """Lemmatise le texte en utilisant spaCy."""
        doc = self.nlp(text)
        return ' '.join([token.lemma_ for token in doc])
    
    def preprocess_text(self, text):
        """
        Applique toutes les √©tapes de pr√©traitement sur un texte.
        
        Args:
            text (str): Texte √† pr√©traiter
            
        Returns:
            str: Texte pr√©trait√©
        """
        if not isinstance(text, str):
            return ''
            
        # Conversion en minuscules
        text = text.lower()
        
        # Suppression des URLs, emojis, mentions et hashtags
        text = self.remove_urls(text)
        text = self.remove_emojis(text)
        text = self.remove_mentions_and_hashtags(text)
        text = self.remove_special_chars(text)
        
        # Lemmatisation
        text = self.lemmatize_text(text)
        
        # Suppression des stop words
        words = text.split()
        words = [word for word in words if word not in self.stop_words]
        
        return ' '.join(words)
    
    def preprocess_dataset(self, df, text_column, target_column=None):
        """
        Pr√©traite un dataset complet de tweets.
        
        Args:
            df (pandas.DataFrame): DataFrame contenant les tweets
            text_column (str): Nom de la colonne contenant le texte des tweets
            target_column (str, optional): Nom de la colonne cible
            
        Returns:
            pandas.DataFrame: DataFrame pr√©trait√©
        """
        logger.info("D√©but du pr√©traitement du dataset...")
        
        # Copie du DataFrame pour √©viter de modifier l'original
        df_processed = df.copy()
        
        # Pr√©traitement du texte
        tqdm.pandas(desc="Pr√©traitement des tweets")
        df_processed['processed_text'] = df_processed[text_column].progress_apply(self.preprocess_text)
        
        # Suppression des lignes avec texte vide apr√®s pr√©traitement
        initial_len = len(df_processed)
        df_processed = df_processed[df_processed['processed_text'].str.strip() != '']
        final_len = len(df_processed)
        
        logger.info(f"Pr√©traitement termin√©. {initial_len - final_len} tweets vides supprim√©s.")
        
        return df_processed

def main():
    """Fonction principale pour tester le pr√©traitement."""
    # Exemple d'utilisation
    sample_tweets = pd.DataFrame({
        'text': [
            "J'adore ce nouveau film ! üé¨ #cinema @cinephile",
            "Le service client est horrible... https://example.com",
            "RT @user: Belle journ√©e aujourd'hui ! ‚òÄÔ∏è"
        ],
        'sentiment': [1, 0, 1]  # 1: positif, 0: n√©gatif
    })
    
    preprocessor = TweetPreprocessor(language='french')
    processed_df = preprocessor.preprocess_dataset(sample_tweets, 'text', 'sentiment')
    
    print("\nExemple de tweets pr√©trait√©s :")
    print(processed_df[['text', 'processed_text']].head())

if __name__ == "__main__":
    main() 